FFTrees_fit <- predict(FFTrees_model, heart_train)
# Regression training decisions
#  Positive values are predicted to be 1, negative values are 0
glm_fit <- predict(glm_model, heart_train) > 0
# randomForest training decisions
randomForest_fit <- predict(randomForest_model, heart_train_fac)
# Now calculate fitting accuracies and put in dataframe
# Truth value for training data is heart_train$sex
train_truth <- heart_train$diagnosis
# Put training results together
training_results <- data_frame(FFTrees = mean(FFTrees_fit == train_truth),
glm = mean(glm_fit == train_truth),
randomForest = mean(randomForest_fit == train_truth))
# Plot training results
barplot(height = unlist(training_results),
main = "Training Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# ------------------------------
# Part IV: Prediction Accuacy!
# ------------------------------
# Calculate predictions for each model for heart_test
# FFTrees testing decisions
FFTrees_pred <- predict(FFTrees_model, heart_test)
# Regression testing decisions
#  Positive values are predicted to be 1, negative values are 0
glm_pred <- predict(glm_model, heart_test) >= 0
# randomForest testing decisions
randomForest_pred <- predict(randomForest_model, heart_test_fac)
# Now calculate testing accuracies and put in dataframe
# Truth value for test data is heart_test$sex
test_truth <- heart_test$diagnosis
testing_results <- data_frame(FFTrees = mean(FFTrees_pred == test_truth),
glm = mean(glm_pred == test_truth),
randomForest = mean(randomForest_pred == test_truth))
# Plot testing results
barplot(height = unlist(testing_results),
main = "Testing Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
svm_model <- svm(formula = factor(sex) ~ .,
data = heart_train_fac)
summary(svm_model)
svm_fit <- predict(svm_model, heart_train_fac)
svm_fit
# Put training results together
training_results <- data_frame(FFTrees = mean(FFTrees_fit == train_truth),
glm = mean(glm_fit == train_truth),
randomForest = mean(randomForest_fit == train_truth),
svm = mean(svm_fit == train_truth))
# Plot training results
barplot(height = unlist(training_results),
main = "Training Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# ------------------------------
# Part I: Build Models
# ------------------------------
# Build FFTrees_model
FFTrees_model <- FFTrees(formula = diagnosis ~ .,
data = heart_train)
# Build glm_model
glm_model <- glm(formula = factor(diagnosis) ~ .,
data = heart_train,
family = "binomial")  # For predicting a binary variable
# Build randomForest model
randomForest_model <- randomForest(formula = factor(diagnosis) ~ .,
data = heart_train_fac)
# Build svm model
svm_model <- svm(formula = factor(diagnosis) ~ .,
data = heart_train_fac)
# ------------------------------
# Part II: Explore Models
# ------------------------------
print(FFTrees_model)
summary(FFTrees_model)
print(glm_model)
summary(glm_model)
print(randomForest_model)
summary(randomForest_model)
print(svm_model)
summary(svm_model)
# ------------------------------
# Part III: Training Accuracy
# ------------------------------
# FFTrees training decisions
FFTrees_fit <- predict(FFTrees_model, heart_train)
# Regression training decisions
#  Positive values are predicted to be 1, negative values are 0
glm_fit <- predict(glm_model, heart_train) > 0
# randomForest training decisions
randomForest_fit <- predict(randomForest_model, heart_train_fac)
# svm training decisions
svm_fit <- predict(svm_model, heart_train_fac)
# Now calculate fitting accuracies and put in dataframe
# Truth value for training data is heart_train$sex
train_truth <- heart_train$diagnosis
# Put training results together
training_results <- data_frame(FFTrees = mean(FFTrees_fit == train_truth),
glm = mean(glm_fit == train_truth),
randomForest = mean(randomForest_fit == train_truth),
svm = mean(svm_fit == train_truth))
# Plot training results
barplot(height = unlist(training_results),
main = "Training Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# ------------------------------
# Part IV: Prediction Accuacy!
# ------------------------------
# Calculate predictions for each model for heart_test
# FFTrees testing decisions
FFTrees_pred <- predict(FFTrees_model, heart_test)
# Regression testing decisions
#  Positive values are predicted to be 1, negative values are 0
glm_pred <- predict(glm_model, heart_test) >= 0
# randomForest testing decisions
randomForest_pred <- predict(randomForest_model, heart_test_fac)
# svm testing decisions
svm_pred <- predict(svm_model, heart_test_fac)
# Now calculate testing accuracies and put in dataframe
# Truth value for test data is heart_test$sex
test_truth <- heart_test$diagnosis
testing_results <- data_frame(FFTrees = mean(FFTrees_pred == test_truth),
glm = mean(glm_pred == test_truth),
randomForest = mean(randomForest_pred == test_truth),
svm = mean(svm_pred == test_truth))
# Plot testing results
barplot(height = unlist(testing_results),
main = "Testing Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# Build svm model
svm_model <- svm(formula = factor(diagnosis) ~ .,
data = heart_train_fac)
print(svm_model)
summary(svm_model)
# svm training decisions
svm_fit <- predict(svm_model, heart_train_fac)
# Now calculate fitting accuracies and put in dataframe
# Truth value for training data is heart_train$sex
train_truth <- heart_train$diagnosis
# Put training results together
training_results <- data_frame(FFTrees = mean(FFTrees_fit == train_truth),
glm = mean(glm_fit == train_truth),
randomForest = mean(randomForest_fit == train_truth),
svm = mean(svm_fit == train_truth))
# Plot training results
barplot(height = unlist(training_results),
main = "Training Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# svm testing decisions
svm_pred <- predict(svm_model, heart_test_fac)
# Now calculate testing accuracies and put in dataframe
# Truth value for test data is heart_test$sex
test_truth <- heart_test$diagnosis
testing_results <- data_frame(FFTrees = mean(FFTrees_pred == test_truth),
glm = mean(glm_pred == test_truth),
randomForest = mean(randomForest_pred == test_truth),
svm = mean(svm_pred == test_truth))
# Plot testing results
barplot(height = unlist(testing_results),
main = "Testing Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# Savew first 125 rows as heart_train and remaining as heart_test
heart_train <- heart %>% slice(1:250)
heart_test <- heart %>% slice(251:nrow(heart))
# Create heart_train_fact, heart_test_fact
#  Just heart_train and hear_test with factors
#  We're only doing this because the randomForest() function
#   requires factors!!!!
heart_train_fac <- heart_train
heart_test_fac <- heart_test
for(i in 1:ncol(heart_train_fac)) {  # Convert character columns and diagnosis to factor
if(class(heart_train_fac[[i]]) == "character") {
heart_train_fac[[i]] <- factor(heart_train_fac[[i]])
heart_test_fac[[i]] <- factor(heart_test_fac[[i]])
}}
# ------------------------------
# Part I: Build Models
# ------------------------------
# Build FFTrees_model
FFTrees_model <- FFTrees(formula = sex ~ .,
data = heart_train)
# Build glm_model
glm_model <- glm(formula = factor(sex) ~ .,
data = heart_train,
family = "binomial")  # For predicting a binary variable
# Build randomForest model
randomForest_model <- randomForest(formula = factor(sex) ~ .,
data = heart_train_fac)
# ------------------------------
# Part II: Explore Models
# ------------------------------
print(FFTrees_model)
summary(FFTrees_model)
print(glm_model)
summary(glm_model)
print(randomForest_model)
summary(randomForest_model)
# ------------------------------
# Part III: Training Accuracy
# ------------------------------
# FFTrees training decisions
FFTrees_fit <- predict(FFTrees_model, heart_train)
# Regression training decisions
#  Positive values are predicted to be 1, negative values are 0
glm_fit <- predict(glm_model, heart_train) > 0
# randomForest training decisions
randomForest_fit <- predict(randomForest_model, heart_train_fac)
# Now calculate fitting accuracies and put in dataframe
# Truth value for training data is heart_train$sex
train_truth <- heart_train$sex
# Put training results together
training_results <- data_frame(FFTrees = mean(FFTrees_fit == train_truth),
glm = mean(glm_fit == train_truth),
randomForest = mean(randomForest_fit == train_truth))
# Plot training results
barplot(height = unlist(training_results),
main = "Training Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# ------------------------------
# Part IV: Prediction Accuacy!
# ------------------------------
# Calculate predictions for each model for heart_test
# FFTrees testing decisions
FFTrees_pred <- predict(FFTrees_model, heart_test)
# Regression testing decisions
#  Positive values are predicted to be 1, negative values are 0
glm_pred <- predict(glm_model, heart_test) >= 0
# randomForest testing decisions
randomForest_pred <- predict(randomForest_model, heart_test_fac)
# Now calculate testing accuracies and put in dataframe
# Truth value for test data is heart_test$sex
test_truth <- heart_test$sex
testing_results <- data_frame(FFTrees = mean(FFTrees_pred == test_truth),
glm = mean(glm_pred == test_truth),
randomForest = mean(randomForest_pred == test_truth))
# Plot testing results
barplot(height = unlist(testing_results),
main = "Testing Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
library(e1071)          # for svm()
library(randomForest)   # for randomForest()
library(rpart)          # for rpart()
library(yarrr)          # for pirateplot()
library(tidyverse)      # for datawrangling and ggplot2
library(FFTrees)        # for the heartdisease data
library(e1071)          # for svm()
library(randomForest)   # for randomForest()
library(rpart)          # for rpart()
library(yarrr)          # for pirateplot()
library(tidyverse)      # for datawrangling and ggplot2
library(FFTrees)        # for the heartdisease data
# -----------------------------------------------
# A step-by-step tutorial for conducting machine learning
# In this tutorial, we'll see how well 3 different models can
#  predict medical data
# ------------------------------------------------
# -----------------------
# Part A:
# Load libraries
# -----------------------
library(e1071)          # for svm()
library(randomForest)   # for randomForest()
library(rpart)          # for rpart()
library(yarrr)          # for pirateplot()
library(tidyverse)      # for datawrangling and ggplot2
library(FFTrees)        # for the heartdisease data
# -----------------------
# Part B: Create datasets
#  heart_train, heart_test
#  heart_train_fac, heart_test_fac
# -----------------------
heart <- heartdisease   # Save a copy of the heartdisease data as heart
set.seed(101)   # To fix the training / test randomization
# Randomly sort rows
heart <- heart %>%
arrange(rnorm(nrow(heart)))
# Savew first 125 rows as heart_train and remaining as heart_test
heart_train <- heart %>% slice(1:100)
heart_test <- heart %>% slice(101:nrow(heart))
# Create heart_train_fact, heart_test_fact
#  Just heart_train and hear_test with factors
#  We're only doing this because the randomForest() function
#   requires factors!!!!
heart_train_fac <- heart_train
heart_test_fac <- heart_test
for(i in 1:ncol(heart_train_fac)) {  # Convert character columns and diagnosis to factor
if(class(heart_train_fac[[i]]) == "character") {
heart_train_fac[[i]] <- factor(heart_train_fac[[i]])
heart_test_fac[[i]] <- factor(heart_test_fac[[i]])
}}
# ------------------------------
# Part I: Build Models
# ------------------------------
# Build FFTrees_model
FFTrees_model <- FFTrees(formula = sex ~ .,
data = heart_train)
# Build glm_model
glm_model <- glm(formula = factor(sex) ~ .,
data = heart_train,
family = "binomial")  # For predicting a binary variable
# Build randomForest model
randomForest_model <- randomForest(formula = factor(sex) ~ .,
data = heart_train_fac)
# ------------------------------
# Part II: Explore Models
# ------------------------------
print(FFTrees_model)
summary(FFTrees_model)
print(glm_model)
summary(glm_model)
print(randomForest_model)
summary(randomForest_model)
# ------------------------------
# Part III: Training Accuracy
# ------------------------------
# FFTrees training decisions
FFTrees_fit <- predict(FFTrees_model, heart_train)
# Regression training decisions
#  Positive values are predicted to be 1, negative values are 0
glm_fit <- predict(glm_model, heart_train) > 0
# randomForest training decisions
randomForest_fit <- predict(randomForest_model, heart_train_fac)
# Now calculate fitting accuracies and put in dataframe
# Truth value for training data is heart_train$sex
train_truth <- heart_train$sex
# Put training results together
training_results <- data_frame(FFTrees = mean(FFTrees_fit == train_truth),
glm = mean(glm_fit == train_truth),
randomForest = mean(randomForest_fit == train_truth))
# Plot training results
barplot(height = unlist(training_results),
main = "Training Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# ------------------------------
# Part IV: Prediction Accuacy!
# ------------------------------
# Calculate predictions for each model for heart_test
# FFTrees testing decisions
FFTrees_pred <- predict(FFTrees_model, heart_test)
# Regression testing decisions
#  Positive values are predicted to be 1, negative values are 0
glm_pred <- predict(glm_model, heart_test) >= 0
# randomForest testing decisions
randomForest_pred <- predict(randomForest_model, heart_test_fac)
# Now calculate testing accuracies and put in dataframe
# Truth value for test data is heart_test$sex
test_truth <- heart_test$sex
testing_results <- data_frame(FFTrees = mean(FFTrees_pred == test_truth),
glm = mean(glm_pred == test_truth),
randomForest = mean(randomForest_pred == test_truth))
# Plot testing results
barplot(height = unlist(testing_results),
main = "Testing Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# Build FFTrees_model
FFTrees_model <- FFTrees(formula = diagnosis ~ .,
data = heart_train)
# Build glm_model
glm_model <- glm(formula = factor(diagnosis) ~ .,
data = heart_train,
family = "binomial")  # For predicting a binary variable
# Build randomForest model
randomForest_model <- randomForest(formula = factor(diagnosis) ~ .,
data = heart_train_fac)
rm(list = ls)
rm(list = ls())
# Chunk 1
knitr::include_graphics("https://uploads.toptal.io/blog/image/443/toptal-blog-image-1407508081138.png")
# Chunk 2
knitr::opts_chunk$set(comment=NA, fig.width=6, fig.height=6, echo = TRUE, eval = TRUE, fig.align = 'center')
# Chunk 3
library(e1071)          # for svm()
library(randomForest)   # for randomForest()
library(rpart)          # for rpart()
library(yarrr)          # for pirateplot()
library(tidyverse)      # for datawrangling and ggplot2
library(FFTrees)        # for the heartdisease data
# Chunk 5
# Build FFTrees_model
FFTrees_model <- FFTrees(formula = diagnosis ~ .,
data = heart_train)
# Build glm_model
glm_model <- glm(formula = factor(diagnosis) ~ .,
data = heart_train,
family = "binomial")  # For predicting a binary variable
# Build randomForest model
randomForest_model <- randomForest(formula = factor(diagnosis) ~ .,
data = heart_train_fac)
# -----------------------------------------------
# A step-by-step tutorial for conducting machine learning
# In this tutorial, we'll see how well 3 different models can
#  predict medical data
# ------------------------------------------------
# -----------------------
# Part A:
# Load libraries
# -----------------------
library(e1071)          # for svm()
library(randomForest)   # for randomForest()
library(rpart)          # for rpart()
library(yarrr)          # for pirateplot()
library(tidyverse)      # for datawrangling and ggplot2
library(FFTrees)        # for the heartdisease data
# -----------------------
# Part B: Create datasets
#  heart_train, heart_test
#  heart_train_fac, heart_test_fac
# -----------------------
heart <- heartdisease   # Save a copy of the heartdisease data as heart
set.seed(101)   # To fix the training / test randomization
# Randomly sort rows
heart <- heart %>%
arrange(rnorm(nrow(heart)))
# Savew first 125 rows as heart_train and remaining as heart_test
heart_train <- heart %>% slice(1:100)
heart_test <- heart %>% slice(101:nrow(heart))
# Create heart_train_fact, heart_test_fact
#  Just heart_train and hear_test with factors
#  We're only doing this because the randomForest() function
#   requires factors!!!!
heart_train_fac <- heart_train
heart_test_fac <- heart_test
for(i in 1:ncol(heart_train_fac)) {  # Convert character columns and diagnosis to factor
if(class(heart_train_fac[[i]]) == "character") {
heart_train_fac[[i]] <- factor(heart_train_fac[[i]])
heart_test_fac[[i]] <- factor(heart_test_fac[[i]])
}}
# ------------------------------
# Part I: Build Models
# ------------------------------
# Build FFTrees_model
FFTrees_model <- FFTrees(formula = sex ~ .,
data = heart_train)
# Build glm_model
glm_model <- glm(formula = factor(sex) ~ .,
data = heart_train,
family = "binomial")  # For predicting a binary variable
# Build randomForest model
randomForest_model <- randomForest(formula = factor(sex) ~ .,
data = heart_train_fac)
# ------------------------------
# Part II: Explore Models
# ------------------------------
print(FFTrees_model)
summary(FFTrees_model)
print(glm_model)
summary(glm_model)
print(randomForest_model)
summary(randomForest_model)
# ------------------------------
# Part III: Training Accuracy
# ------------------------------
# FFTrees training decisions
FFTrees_fit <- predict(FFTrees_model, heart_train)
# Regression training decisions
#  Positive values are predicted to be 1, negative values are 0
glm_fit <- predict(glm_model, heart_train) > 0
# randomForest training decisions
randomForest_fit <- predict(randomForest_model, heart_train_fac)
# Now calculate fitting accuracies and put in dataframe
# Truth value for training data is heart_train$sex
train_truth <- heart_train$sex
# Put training results together
training_results <- data_frame(FFTrees = mean(FFTrees_fit == train_truth),
glm = mean(glm_fit == train_truth),
randomForest = mean(randomForest_fit == train_truth))
# Plot training results
barplot(height = unlist(training_results),
main = "Training Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# ------------------------------
# Part IV: Prediction Accuacy!
# ------------------------------
# Calculate predictions for each model for heart_test
# FFTrees testing decisions
FFTrees_pred <- predict(FFTrees_model, heart_test)
# Regression testing decisions
#  Positive values are predicted to be 1, negative values are 0
glm_pred <- predict(glm_model, heart_test) >= 0
# randomForest testing decisions
randomForest_pred <- predict(randomForest_model, heart_test_fac)
# Now calculate testing accuracies and put in dataframe
# Truth value for test data is heart_test$sex
test_truth <- heart_test$sex
testing_results <- data_frame(FFTrees = mean(FFTrees_pred == test_truth),
glm = mean(glm_pred == test_truth),
randomForest = mean(randomForest_pred == test_truth))
# Plot testing results
barplot(height = unlist(testing_results),
main = "Testing Results",
ylim = c(0, 1),
col = c("palegreen3", "wheat2", "orchid3"))
# Build FFTrees_model
FFTrees_model <- FFTrees(formula = diagnosis ~ .,
data = heart_train)
# Build glm_model
glm_model <- glm(formula = factor(diagnosis) ~ .,
data = heart_train,
family = "binomial")  # For predicting a binary variable
# Build randomForest model
randomForest_model <- randomForest(formula = factor(diagnosis) ~ .,
data = heart_train_fac)
